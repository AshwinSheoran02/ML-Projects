{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('BitcoinHeistData.csv')\n",
    "df = df.dropna()  ## dropping null values\n",
    "\n",
    "df  = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>year</th>\n",
       "      <th>day</th>\n",
       "      <th>length</th>\n",
       "      <th>weight</th>\n",
       "      <th>count</th>\n",
       "      <th>looped</th>\n",
       "      <th>neighbors</th>\n",
       "      <th>income</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1875414</th>\n",
       "      <td>19JDMrubNSMKWMd4aefexqt5SSiGzYnhtq</td>\n",
       "      <td>2016</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>2.187500</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>135200000.0</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192664</th>\n",
       "      <td>1JvusjLkvuBYCfgxw6KwX8HnDVb3pjSjZJ</td>\n",
       "      <td>2014</td>\n",
       "      <td>66</td>\n",
       "      <td>144</td>\n",
       "      <td>0.013911</td>\n",
       "      <td>1550</td>\n",
       "      <td>1208</td>\n",
       "      <td>2</td>\n",
       "      <td>45128303.0</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080058</th>\n",
       "      <td>1FdCjMvaPs8njsLKgjZekQDhBKLGX1Q37Z</td>\n",
       "      <td>2013</td>\n",
       "      <td>319</td>\n",
       "      <td>4</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>101351351.0</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291877</th>\n",
       "      <td>1FZkDZdhReaCVnTZ2eDZTw7qhTqH9jkqaU</td>\n",
       "      <td>2011</td>\n",
       "      <td>261</td>\n",
       "      <td>6</td>\n",
       "      <td>0.145483</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>100908523.0</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442389</th>\n",
       "      <td>1Di1T4H7FR67Pq2YubkESKkEA5dNE9DuhH</td>\n",
       "      <td>2014</td>\n",
       "      <td>316</td>\n",
       "      <td>144</td>\n",
       "      <td>0.088939</td>\n",
       "      <td>3642</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>297208000.0</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2566014</th>\n",
       "      <td>1N3sbxkwwzfg65u32Tpz5x3DuVNZ1FWGKR</td>\n",
       "      <td>2017</td>\n",
       "      <td>345</td>\n",
       "      <td>16</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>59080704.0</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756183</th>\n",
       "      <td>1EHocpqQ8wwk623mhwVFG5om6njqyLb2Pe</td>\n",
       "      <td>2018</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>64740171.0</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920539</th>\n",
       "      <td>1DjcZ9GdvLZuhAhctbQggfohYTWf21XN8H</td>\n",
       "      <td>2016</td>\n",
       "      <td>64</td>\n",
       "      <td>144</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>5446</td>\n",
       "      <td>5378</td>\n",
       "      <td>2</td>\n",
       "      <td>31100000.0</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852642</th>\n",
       "      <td>1NAG5f4iuUhgqA8Qhm9coRundm3Yvh3NcF</td>\n",
       "      <td>2015</td>\n",
       "      <td>361</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>151178747.0</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034002</th>\n",
       "      <td>1NWpf8mGxcAe5wiY5XUmck9cdUAeQMBJfw</td>\n",
       "      <td>2016</td>\n",
       "      <td>178</td>\n",
       "      <td>4</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>361176000.0</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2916697 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    address  year  day  length    weight  \\\n",
       "1875414  19JDMrubNSMKWMd4aefexqt5SSiGzYnhtq  2016   19      12  2.187500   \n",
       "1192664  1JvusjLkvuBYCfgxw6KwX8HnDVb3pjSjZJ  2014   66     144  0.013911   \n",
       "1080058  1FdCjMvaPs8njsLKgjZekQDhBKLGX1Q37Z  2013  319       4  0.250000   \n",
       "291877   1FZkDZdhReaCVnTZ2eDZTw7qhTqH9jkqaU  2011  261       6  0.145483   \n",
       "1442389  1Di1T4H7FR67Pq2YubkESKkEA5dNE9DuhH  2014  316     144  0.088939   \n",
       "...                                     ...   ...  ...     ...       ...   \n",
       "2566014  1N3sbxkwwzfg65u32Tpz5x3DuVNZ1FWGKR  2017  345      16  0.015625   \n",
       "2756183  1EHocpqQ8wwk623mhwVFG5om6njqyLb2Pe  2018  170       0  0.500000   \n",
       "1920539  1DjcZ9GdvLZuhAhctbQggfohYTWf21XN8H  2016   64     144  0.000905   \n",
       "1852642  1NAG5f4iuUhgqA8Qhm9coRundm3Yvh3NcF  2015  361       0  1.000000   \n",
       "2034002  1NWpf8mGxcAe5wiY5XUmck9cdUAeQMBJfw  2016  178       4  0.250000   \n",
       "\n",
       "         count  looped  neighbors       income  label  \n",
       "1875414      4       0          2  135200000.0  white  \n",
       "1192664   1550    1208          2   45128303.0  white  \n",
       "1080058      2       0          2  101351351.0  white  \n",
       "291877      27      26          3  100908523.0  white  \n",
       "1442389   3642       0          2  297208000.0  white  \n",
       "...        ...     ...        ...          ...    ...  \n",
       "2566014      1       0          2   59080704.0  white  \n",
       "2756183      1       0          1   64740171.0  white  \n",
       "1920539   5446    5378          2   31100000.0  white  \n",
       "1852642      1       0          1  151178747.0  white  \n",
       "2034002      1       0          2  361176000.0  white  \n",
       "\n",
       "[2916697 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Splitting into train test and validation datatests\n",
    "train_size = 0.7\n",
    "valid_size=0.15\n",
    "train_index = int(len(df)*train_size)\n",
    "df_train = df[0:train_index]\n",
    "df_rem = df[train_index:]\n",
    "valid_index = int(len(df)*valid_size)\n",
    "\n",
    "df_valid = df[train_index:train_index+valid_index]\n",
    "df_test = df[train_index+valid_index:]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_train.drop(columns=['label' , 'address']).copy(), df_train['label'].copy()\n",
    "X_valid, y_valid = df_valid.drop(columns=['label' , 'address']).copy(), df_valid['label'].copy()\n",
    "X_test, y_test = df_test.drop(columns=['label' , 'address']).copy(), df_test['label'].copy()\n",
    "\n",
    "## Spitting into X and Y data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Train a decision tree using both the Gini index and the Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Max depth 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.985945335606826"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=4 , criterion='entropy') ## criteria has by default gini\n",
    "clf = clf.fit(X_train , y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "clf.score(X_test , y_test)\n",
    "\n",
    "## Reference taken from scikit-learn.org\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Max depth 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9862447600718619"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=8 , criterion='entropy') ## criteria has by default gini\n",
    "clf = clf.fit(X_train , y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "clf.score(X_test , y_test)\n",
    "\n",
    "## Reference taken from scikit-learn.org\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Max depth 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9874447436149447"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=10 , criterion='entropy') ## criteria has by default gini\n",
    "clf = clf.fit(X_train , y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "clf.score(X_test , y_test)\n",
    "\n",
    "## Reference taken from scikit-learn.org\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Max depth 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9882333042289706"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=15 , criterion='entropy') ## criteria has by default gini\n",
    "clf = clf.fit(X_train , y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "clf.score(X_test , y_test)\n",
    "\n",
    "## Reference taken from scikit-learn.org\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Max depth 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9863339017064909"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=20 , criterion='entropy') ## criteria has by default gini\n",
    "clf = clf.fit(X_train , y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "clf.score(X_test , y_test)\n",
    "\n",
    "## Reference taken from scikit-learn.org\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are getting the following results \n",
    "\n",
    "Max depth = 4   Accuracy = 0.9859590497044612\n",
    "\n",
    "Max depth = 8   Accuracy = 0.9862447600718619\n",
    "\n",
    "Max depth = 10  Accuracy = 0.9874424579320055\n",
    "\n",
    "Max depth = 15  Accuracy = 0.9883247315465388\n",
    "\n",
    "Max depth = 20  Accuracy = 0.9862950450965244\n",
    "\n",
    "\n",
    "We are getting best result with  Max Depth = 15 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Ensembling is a method to combine multiple not-so-good models to get a better performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "## We have to create 100 decision stumps\n",
    "stumps=[]\n",
    "for i in range(100):\n",
    "    stumps.append(DecisionTreeClassifier(criterion=\"entropy\",max_depth=3))\n",
    "\n",
    "## Now we have to train it on randomly selected 50% of data\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    X_train_frac=X_train.sample(frac=0.5)\n",
    "    y_train_frac=y_train.loc[X_train_frac.index]\n",
    "    stumps[i].fit(X_train,y_train)\n",
    "## Now we have Trained \n",
    "## Now we have to check the prediction\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy obtained is 0.9858904147162083\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "predicted_samples=[]\n",
    "## The list of predicted samples\n",
    "for i in range(100):\n",
    "    predicts=stumps[i].predict(X_valid)\n",
    "    predicted_samples.append(predicts)\n",
    "\n",
    "new_predicted_samples=[]   ## List of new predicted Sample ( after majority voting of output of stumps)\n",
    "\n",
    "##  Majority voting of output of stumps\n",
    "for i in range(len(predicted_samples[0])):\n",
    "    max_val={}   # creating a dictionary to store the key value pair of y \n",
    "    for j in predicted_samples:\n",
    "        if(j[i] in max_val):\n",
    "            max_val[j[i]]+=1\n",
    "        else:\n",
    "            max_val[j[i]]=1\n",
    "    max_key=max(max_val, key= lambda x: max_val[x])\n",
    "    new_predicted_samples.append(max_key)   ## appeding the y with maximum value of dictionary\n",
    "\n",
    "accuracy=np.sum(np.array(new_predicted_samples)==np.array(y_valid.to_list()))/len(y_valid)   ## Calculating Accuracy \n",
    "\n",
    "print(\"Accuracy obtained is \"+str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy coming from Ensembling by creating 100 different decision stumps on 50% data and predicting the test samples’ labels by taking a majority vote of the output of the stumps is 0.9857715586600351"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C) Use the Adaboost algorithm on the above dataset and report the testing accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9668713114791568"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=15)  , n_estimators=4 )\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)\n",
    "\n",
    "## Reference taken from scikit-learn.org\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9737169318820771"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=15) , n_estimators=8 )\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)\n",
    "\n",
    "## Reference taken from scikit-learn.org\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9765900353366582"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=15) ,    n_estimators=10)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)\n",
    "## Reference taken from scikit-learn.org\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9801739861853324"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=15) , n_estimators=15)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)\n",
    "\n",
    "## Reference taken from scikit-learn.org\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.984343071866443"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "clf = AdaBoostClassifier( DecisionTreeClassifier(max_depth=15)  , n_estimators=20)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)\n",
    "\n",
    "## Reference taken from scikit-learn.org\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using AdaBoost\n",
    "##### Using Max Depth = 15\n",
    "\n",
    "n estimators = 4  Accuracy = 0.9723615218991283\n",
    "\n",
    "n estimators = 8  Accuracy = 0.9765351789461173\n",
    "\n",
    "n estimators = 10  Accuracy = 0.9801031300142169\n",
    "\n",
    "n estimators = 15 Accuracy = 0.8836747381750193\n",
    "\n",
    "n estimators = 20  Accuracy = 0.9844184994034367\n",
    "\n",
    "We are getting the best result with n estimators = 20 and when max depth = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison between Random Forest and Adaboost\n",
    "\n",
    "The best Accuracy that we got with Random Forest was 0.9883247315465388\n",
    "\n",
    "With Adaboost we are getting Accuracy 0.9844184994034367"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "77df3a5ebd1cef01dee7bc6ed82b7377cfd852bb783257559a7f51931db89a34"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
